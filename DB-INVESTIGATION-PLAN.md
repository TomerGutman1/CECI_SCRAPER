# תכנית חקירת שלמות הנתונים ב-DB

## הקשר

דווחו 3 בעיות חמורות במאגר (~25,000 רשומות):

| בעיה | היקף | חומרה |
|------|------|--------|
| החלטות ללא כותרת ("ללא כותרת") | 815 רשומות | גבוהה |
| תקצירים כפולים (אותו תקציר בהחלטות שונות) | 22 זוגות | קריטית |
| הזזת נתונים (summary של 1024 בתוך 1022) | לפחות 1 מאומת | קריטית |

**הנחת עבודה:** זה רק קצה הקרחון. יש לבצע חקירה מקיפה לפני תכנון תיקון.

---

## שלב 1: שאילתות אבחון — הבנת ההיקף

### 1.1 סטטיסטיקה בסיסית

| שאילתה | מטרה |
|---------|------|
| סה"כ רשומות, פילוח לפי `government_number` | מפת הנתונים |
| כותרות חסרות (NULL / ריק / "ללא כותרת") — פילוח לפי ממשלה | האם הבעיה מקומית לממשלה 29? |
| תקצירים חסרים / ריקים | גודל בעיית התקצירים |
| תוכן חסר / קצר (<100 תווים) | החלטות שנגרדו בצורה לקויה |
| תאריכים חסרים / בפורמט שגוי | שלמות הנתונים |

**שאלות שנענה עליהן:**
- האם 815 ה"ללא כותרת" הן רק מממשלה 29?
- האם יש עוד ממשלות עם בעיה דומה?
- כמה רשומות בכלל חסר בהן מידע קריטי?

### 1.2 זיהוי כפילויות

| שאילתה | מטרה |
|---------|------|
| תקצירים כפולים — hash של כל תקציר, קיבוץ | האם יש יותר מ-22? |
| תוכן כפול — hash של כל decision_content | האם יש החלטות עם אותו תוכן? |
| כותרות כפולות (ללא "ללא כותרת") | כפילויות בכותרות |

**שאלות שנענה עליהן:**
- האם 22 הזוגות זה המספר האמיתי, או שיש עוד?
- האם הכפילויות רק בתקצירים, או גם בתוכן?
- האם יש "קבוצות" של 3+ החלטות עם אותו תקציר?

### 1.3 זיהוי הזזת נתונים (Data Shifting)

**המקרה המאומת:** החלטה 36_1022 (הצללה וקירור) מכילה את התקציר של 36_1024 (אמירויות).

| בדיקה | אלגוריתם |
|-------|-----------|
| אימות המקרה 36_1022/36_1024 | שליפה ישירה + השוואת כותרת-תקציר |
| זיהוי הזזות סדרתיות | לכל ממשלה: מיון לפי מספר החלטה → בדיקת שלשות (N-1, N, N+1) |
| התאמת כותרת-תקציר | לכל רשומה: האם מילות מפתח מהכותרת מופיעות בתקציר? |

**אלגוריתם זיהוי הזזה:**
```
לכל ממשלה:
  מיון החלטות לפי מספר (עולה)
  לכל שלשה (prev, curr, next):
    title_kw_prev = extract_keywords(prev.title)  # 5 מילות מפתח
    title_kw_next = extract_keywords(next.title)

    if curr.summary מכיל >=2 מילות מפתח מ-prev.title:
      AND curr.summary לא מכיל מילות מפתח מ-curr.title:
        → backward shift (תקציר מההחלטה הקודמת)

    if curr.summary מכיל >=2 מילות מפתח מ-next.title:
      AND curr.summary לא מכיל מילות מפתח מ-curr.title:
        → forward shift (תקציר מההחלטה הבאה)
```

**מילות עצירה עבריות (לא נספרות כמילות מפתח):**
של, את, על, ב, ל, מ, ה, ו, כ, ש, אל, עם, או, זה, כי, לא, בדבר, החלטה

**שאלות שנענה עליהן:**
- האם ההזזה היא רק בתקצירים? או גם ב-operativity/tags?
- האם ההזזה היא תמיד ב-1 (next/prev), או גם ב-2, 3...?
- כמה החלטות בסה"כ מושפעות?

### 1.4 שלמות מבנית

| בדיקה | מטרה |
|-------|------|
| פורמט decision_key (צריך להיות `{gov}_{num}`) | מפתחות פגומים |
| מפתחות כפולים | הפרת unique constraint |
| `government_number` בשדה vs. ב-key | חוסר עקביות |
| טווח תאריכים (1948–היום) | תאריכים חריגים |

### 1.5 אנומליות (שלב כבד — content)

| בדיקה | מטרה |
|-------|------|
| בעיות encoding (Mojibake, תווי ×, Ã) | קידוד שבור |
| שאריות Cloudflare (Attention Required, Ray ID) | תוכן שנגרד בטעות |
| תוכן חתוך ("המשך התוכן...") | גריפה חלקית |
| תוכן בגודל 32,768 בדיוק | חיתוך DB/scraper |

---

## שלב 2: ניתוח ממצאים

לאחר הרצת כל השאילתות, ננתח:

1. **מפת חומרה** — כמה רשומות מושפעות מכל בעיה
2. **דפוסים** — האם הבעיות מרוכזות בממשלות/תקופות ספציפיות
3. **שורש הבעיה** — האם ההזזה קרתה ב-batch insert? ב-AI processing? בגריפה?
4. **תעדוף** — אילו בעיות לתקן קודם

### שאלות מפתח לניתוח:

- **815 ללא כותרת:** האם ניתן לגרד מחדש מ-gov.il? האם הדפים עדיין קיימים?
- **תקצירים כפולים:** האם 22 הזוגות הם סדרתיים (N, N+1) או אקראיים?
- **הזזת נתונים:** האם מדובר ב-batch ספציפי? אותו sync run?

---

## שלב 3: תכנון מנגנון תיקון (אחרי ניתוח הממצאים)

ייקבע על סמך הממצאים. אפשרויות:

| בעיה | תיקון אפשרי | עלות |
|------|-------------|------|
| ללא כותרת | גריפה מחדש מ-gov.il | $0 (Selenium) |
| תקצירים כפולים | זיהוי + regenerate עם AI | ~$0.01-0.05 |
| הזזת נתונים | זיהוי מדויק + re-scrape + AI | ~$0.01-0.05 למושפעת |
| תוכן חסר/קצר | re-scrape | $0 |
| Cloudflare remnants | re-scrape + AI | ~$0.01 למושפעת |

---

## כלים טכניים

**גישה ל-DB:** Python Supabase client (REST API) — אין psql ישיר

**מגבלות:**
- מקסימום 1,000 רשומות per query — צריך pagination
- אין GROUP BY / COUNT ב-REST API — אגרגציה ב-Python
- שליפת כל 25K רשומות אפשרית אבל כבדה עם content

**פונקציה קיימת:** `fetch_records_for_qa()` ב-`src/gov_scraper/processors/qa.py` — כבר מטפלת ב-pagination

**סקריפט:** `bin/investigate_db.py` (כבר נוצר — מוכן להרצה)

---

## סדר ביצוע מוצע

```
שלב 1: הרצת שאילתות אבחון (phases 1-3)
  ↓
שלב 2: ניתוח ממצאים + זיהוי דפוסים
  ↓
שלב 3: הרצת בדיקות נוספות (phases 4-5) לפי הצורך
  ↓
שלב 4: תכנון מנגנון תיקון על סמך ממצאים
  ↓
שלב 5: ביצוע תיקונים (preview → dry-run → execute)
```

---

## פקודות הרצה

```bash
# חקירה מהירה — שלבים 1-3
python bin/investigate_db.py --phase 1 2 3

# חקירה מלאה — כל 5 השלבים
python bin/investigate_db.py --verbose

# בדיקת מקרה ספציפי (הזזת 36_1022)
python bin/investigate_db.py --phase 3 --verbose

# הגבלה ל-1000 רשומות (לבדיקה)
python bin/investigate_db.py --phase 1 2 3 --max 1000

# דילוג על שלב 5 (כבד — דורש content)
python bin/investigate_db.py --skip-content
```

**הפלט:** דוח JSON מפורט ב-`data/qa_reports/db_investigation_YYYYMMDD_HHMMSS.json` + סיכום בקונסול.
